"""
Script de test pour valider l'installation du Data Lake
"""
import sys
from pathlib import Path
from datetime import datetime

# Couleurs pour l'affichage
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
RESET = '\033[0m'


def print_success(message):
    print(f"{GREEN}‚úì{RESET} {message}")


def print_error(message):
    print(f"{RED}‚úó{RESET} {message}")


def print_warning(message):
    print(f"{YELLOW}‚ö†{RESET} {message}")


def test_imports():
    """Test des imports Python"""
    print("\n1. Test des imports Python...")
    
    try:
        import pandas
        print_success(f"pandas {pandas.__version__}")
    except ImportError:
        print_error("pandas non install√©")
        return False
    
    try:
        import pyarrow
        print_success(f"pyarrow {pyarrow.__version__}")
    except ImportError:
        print_error("pyarrow non install√©")
        return False
    
    try:
        import requests
        print_success(f"requests {requests.__version__}")
    except ImportError:
        print_error("requests non install√©")
        return False
    
    return True


def test_configuration():
    """Test de la configuration"""
    print("\n2. Test de la configuration...")
    
    try:
        from data_lake_config import (
            DATA_LAKE_ROOT, STREAMS_DIR, TABLES_DIR,
            FEEDS_DIR, LOGS_DIR, STREAMS_CONFIG, TABLES_CONFIG
        )
        print_success("Configuration charg√©e")
        print(f"   Racine: {DATA_LAKE_ROOT}")
        print(f"   Streams: {len(STREAMS_CONFIG)}")
        print(f"   Tables: {len(TABLES_CONFIG)}")
        return True
    except Exception as e:
        print_error(f"Erreur de configuration: {e}")
        return False


def test_directory_structure():
    """Test de la structure de dossiers"""
    print("\n3. Test de la structure de dossiers...")
    
    try:
        from data_lake_config import ensure_directories, DATA_LAKE_ROOT
        
        ensure_directories()
        
        required_dirs = [
            DATA_LAKE_ROOT,
            DATA_LAKE_ROOT / "streams",
            DATA_LAKE_ROOT / "tables",
            DATA_LAKE_ROOT / "feeds",
            DATA_LAKE_ROOT / "feeds" / "active",
            DATA_LAKE_ROOT / "feeds" / "archived",
            DATA_LAKE_ROOT / "logs"
        ]
        
        all_exist = True
        for directory in required_dirs:
            if directory.exists():
                print_success(f"{directory.name}/ existe")
            else:
                print_error(f"{directory.name}/ manquant")
                all_exist = False
        
        return all_exist
    except Exception as e:
        print_error(f"Erreur lors de la cr√©ation des dossiers: {e}")
        return False


def test_feed_management():
    """Test de la gestion des feeds"""
    print("\n4. Test de la gestion des feeds...")
    
    try:
        from manage_feeds import FeedManager
        
        manager = FeedManager()
        print_success("FeedManager initialis√©")
        
        # Compter les feeds actifs
        active_feeds = list(manager.active_dir.glob("*.json"))
        print(f"   Feeds actifs: {len(active_feeds)}")
        
        return True
    except Exception as e:
        print_error(f"Erreur de gestion des feeds: {e}")
        return False


def test_metadata_utils():
    """Test des utilitaires de m√©tadonn√©es"""
    print("\n5. Test des utilitaires de m√©tadonn√©es...")
    
    try:
        from metadata_utils import MetadataReader, MetadataAnalyzer
        
        print_success("MetadataReader disponible")
        print_success("MetadataAnalyzer disponible")
        
        # Test de lecture des m√©tadonn√©es
        all_metadata = MetadataReader.list_all_metadata()
        print(f"   Streams avec m√©tadonn√©es: {len(all_metadata['streams'])}")
        print(f"   Tables avec m√©tadonn√©es: {len(all_metadata['tables'])}")
        
        return True
    except Exception as e:
        print_error(f"Erreur des utilitaires: {e}")
        return False


def test_parquet_write():
    """Test d'√©criture Parquet"""
    print("\n6. Test d'√©criture Parquet...")
    
    try:
        import pandas as pd
        import pyarrow.parquet as pq
        from data_lake_config import DATA_LAKE_ROOT
        
        # Cr√©er un DataFrame de test
        df = pd.DataFrame({
            'id': [1, 2, 3],
            'value': ['a', 'b', 'c'],
            'timestamp': [datetime.now()] * 3
        })
        
        # √âcrire en Parquet
        test_file = DATA_LAKE_ROOT / "test.parquet"
        df.to_parquet(test_file, compression='snappy')
        
        # Lire et v√©rifier
        df_read = pd.read_parquet(test_file)
        
        if len(df_read) == 3:
            print_success("√âcriture/lecture Parquet OK")
            test_file.unlink()  # Supprimer le fichier de test
            return True
        else:
            print_error("Donn√©es Parquet incorrectes")
            return False
    except Exception as e:
        print_error(f"Erreur Parquet: {e}")
        return False


def test_ksqldb_connection():
    """Test de connexion √† ksqlDB (optionnel)"""
    print("\n7. Test de connexion ksqlDB (optionnel)...")
    
    try:
        from data_lake_config import KSQLDB_CONFIG
        import requests
        
        url = f"http://{KSQLDB_CONFIG['host']}:{KSQLDB_CONFIG['port']}/info"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            print_success("ksqlDB accessible")
            info = response.json()
            print(f"   Version: {info.get('KsqlServerInfo', {}).get('version', 'N/A')}")
            return True
        else:
            print_warning("ksqlDB non accessible (optionnel)")
            return True  # Non bloquant
    except Exception as e:
        print_warning(f"ksqlDB non accessible: {e} (optionnel)")
        return True  # Non bloquant


def main():
    """Ex√©cute tous les tests"""
    print("=" * 60)
    print("üß™ TEST DE L'INSTALLATION DU DATA LAKE")
    print("=" * 60)
    
    tests = [
        ("Imports Python", test_imports),
        ("Configuration", test_configuration),
        ("Structure de dossiers", test_directory_structure),
        ("Gestion des feeds", test_feed_management),
        ("Utilitaires m√©tadonn√©es", test_metadata_utils),
        ("√âcriture Parquet", test_parquet_write),
        ("Connexion ksqlDB", test_ksqldb_connection)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print_error(f"Erreur inattendue: {e}")
            results.append((name, False))
    
    # R√©sum√©
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = f"{GREEN}PASS{RESET}" if result else f"{RED}FAIL{RESET}"
        print(f"{status} - {name}")
    
    print("\n" + "-" * 60)
    print(f"R√©sultat: {passed}/{total} tests r√©ussis")
    
    if passed == total:
        print(f"\n{GREEN}‚úì Installation valid√©e avec succ√®s!{RESET}")
        print("\nProchaines √©tapes:")
        print("  1. Configurer ksqlDB dans data_lake_config.py")
        print("  2. Synchroniser les feeds: python manage_feeds.py sync")
        print("  3. Lancer un export: python export_to_data_lake.py --all")
        return 0
    else:
        print(f"\n{RED}‚úó Certains tests ont √©chou√©{RESET}")
        print("\nV√©rifiez:")
        print("  1. Les d√©pendances sont install√©es: pip install -r requirements.txt")
        print("  2. Les permissions sur les dossiers")
        print("  3. La configuration dans data_lake_config.py")
        return 1


if __name__ == "__main__":
    sys.exit(main())
